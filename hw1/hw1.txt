Problem 1: Warehouse Scale Computers
a.True: 
According to The Datacenter as a Computer, “Nodes in a large MSP may communicate at latencies on the order of 100 ns, whereas the LAN-based networks usually deployed in clusters of servers will experience latencies at or above 100 micro second.” Therefore, the workloads with intensive communication patterns will perform significantly better in a 128 processor-core SMP than in an Ethernet-connected cluster of 32 four-core low-end servers. 

b.False: 
As the authors of The Datacenter as a Computer noted in their book, “Clusters of low-end servers are the preferred building blocks for WSCs today.” One of their reasoning is that the low-end server platforms share many key components with the very high-volume personal computing market; consequently, they benefit more substantially from economies scale.
Since the cost-efficiency comparison is hard due to benchmarking, they compare two HP products that benchmarked with the same amount to support their reasoning. Based on Table 3.1, which is the summary of these two products, we can see the ProLiant, the PC-class server, is about four times more cost-efficient than the Superdome, the SMP server. They also mention at the end of their Table 3.1 analysis that, “If we eliminate discounts in both cases, the ProLiant server hardware becomes roughly 20 times more cost-efficient than the Superdome”, which is a high gap between their costs. 

c.True: 
As mentioned in Chapter 5, an efficiency metric equation can be part up into three components, which are a facility term, a server energy conversion term, and the efficiency of the electronic components in performing the computation per se. Efficiency calculation which is the Power Using Effectiveness, PUE, reflects the quality of the datacenter building infrastructure itself, and captures the ratio of total building power to IT power; the power consumed by the actual computing equipment, such as servers and network equipments.
It will violate the law of conservation of energy by going below one. We always need some power for infrastructure. It is stated in The Datacenter as a Computer, “Based on the current state of the art, an annual TPUE of 1.25 probably represents the upper limit of what is economically feasible in real-world settings.”

d.False: 
Although the cost of IT Equipment is hieh, based on the lecture notes, companies need to change the every 3-10 years. Based on the Figure 5.2 in The Datacenter as a Computer higher percentage of energy is being used in chillers rather than IT Equipment.

e.False: 
As we know, linear systems are ZIZO; Zero Input produces Zero Output. This means that for zero utilization we should have use zero power, but based on the lecture notes, we using 50 MW energy.


Problem 2: MapReduce Questions
a.
Combiner is an optional processing step of optimization on the MapReduce job. The combiner as a function can be run on the output of the map phase to filter or combine steps to lessen the number of intermediate keys that are being passed to the reducer. The combiner works a “mini reduce” process, which operates only on data generated by one machine.
As an example, we can use the word count example, which is discussed in the lecture notes. In this example, mapper output (word, 1) pairs. Using combiner, the program can be speed up by gathering all the output in-memory lists and then calling the combiner on each of the words to emits word and the number of its occurrence in that part of the input as a pair, (word, count_of_occurrence). Now reducer will work on the fewer pairs.

b.
When only map and reduce are performed in a task, the reducer will consume the key/value pairs emitted by the mapper. Therefore, the output(key/value pairs) of the mapper should be the same as the input(key/value pairs) of reducer. As it is explained in the previous part, the intermediate key/value pairs are getting combined in the combiner of the same node as the map before being send to the reducer. In other words, the combiner reduces the network traffic between the mapper and the reducer. So when combiner is being used, the input key/value pairs have to be the same as the key/value pairs so the reducer can interact with data it is passing to it. If not, then the program will give a run time error.
Note: reducer should work with or without the combiner. So the key/value pairs it gets from the combiner has the be the same as what it will get from the mapper if there wasn't any combiner.

c.
Yes, the combiners can start as early as the map function generates the intermediate results and send them to the buffer. The process of combining is in parallel with the map function. For instance, the combining process in the lecture note example starts as early as any of the map function is done with its job. 
In other words, the combing process can be start as early as any of the map function is done with its job.

d.
Yes. As we know, MapReduce is a programming model that is used for processing and generating large data sets. Based on The Datacenter as a Computer, if we assume the Web to contain 100 billion documents, with an average document size of 4 KB, the haystack is about 400TB. Now suppose the query “new york restaurants” is being searched. The searching algorithm will traverse through the list of appearances of each of the given word and rank them based on other components such as overall importance of the document, the number of occurrences, and positions. For any word that is given to a search engine, its hash code can be calculated. So it can be determined which part of the network has the information regarding to that word.
If searching process does not use parallelism and MapReduce, it will take for a long time to get back the result. So MapReduce has to be used on these huge data sets. 

e.
No, because map and reduce get chuncks of data. So there is no way that these datas get shared in different phase of map or/and reduce.


Problem 3: MapReduce Programming
a.
By traversing through all the emails and counting the number of appearance of all the words in them we can figure out the correlation between words and the spam emails. By assigning negative one to each word that appears in spam email and positive one to the words that appear in non-spma emails and using MapReduce we can find the comulative number of all these different words appearing in spam or non-spam emails. Therefore, we can find the correlation of each word with spam and non-spam emails. 

b.
In the map part, mapper get two arguments; key which represents if the email that is reading is spam or not and text_content which is content of the email passed to it. Mapper will read word by word and based on beig spam or not it will assign one ro negative one to ir respectively. 

/* Inputs:
 * key: Either True (for being spam) or False (for not being spam)
 * value: Text content of an email
 * output:
 * Either (word, +1) or (word, -1)
*/
Map(Boolean key, String text_content):                   
   If (key is True):         	// If it is a spam email
      For word in value:
      	  EmitIntermediate(word, -1)
   Else:			// If it is not a spam email
      For word in value:
      	  EmitIntermediate(word, 1)

c.
Combiner combines the results of mapper by adding up all the assigned value of the same words. So the output of the combiner is the number of occurrence of the word in the email.
Note: If the email is spam, the total number of occurrence of all of its words are negative while for non-spam emails it is positive. 

/*
 *Inputs: Input to the combiner is the result of the mapper
 *Interm_key:word
 *Intermediate_value: a list of (word, +/-1)
 *Output: Words and their number of occurence
*/
Combiner(Object interm_key, Iterable intermediate_value):     	
   TotalOccurence = 0
      For number in intermediate_value:
      	  TotalOccurence = TotalOccurence + number
   Output(word, TotalOccurence)

d.
Reducer combines the results of each word and categorized it to negative if it is word that moslty apper in spam emails and postitive otherwise.

/*
 *Inputs: the same as combiner
 *Outputs: Negative if the word is more being used in spam emails and positive if the word is more being used in non-spam email. 
*/	
Reduce(Object interm_key, Object value):
   count = 0
   For number in value:
       count = count + number
   If(count < -5):
       Output(interm_key, Negative)
   Else if(count > 5):
       Output(interm_key, Positive)


Problem 4: Do in hw1.c
